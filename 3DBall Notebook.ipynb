{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8351d39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlagents\n",
    "from mlagents_envs.environment import UnityEnvironment as UE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "daaeebb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = UE(file_name=\"UnityEnvironment\", seed=1, side_channels=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dacb0af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ded3a458",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['3DBall?team=0']\n",
      "3DBall?team=0\n"
     ]
    }
   ],
   "source": [
    "print(list(env.behavior_specs))\n",
    "behavior_name = list(env.behavior_specs)[0]\n",
    "print(behavior_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b072c64e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'mlagents_envs.base_env.BehaviorSpec'>\n",
      "\n",
      "BehaviorSpec(observation_specs=[ObservationSpec(shape=(8,), dimension_property=(<DimensionProperty.UNSPECIFIED: 0>,), observation_type=<ObservationType.DEFAULT: 0>, name='')], action_spec=ActionSpec(continuous_size=2, discrete_branches=()))\n"
     ]
    }
   ],
   "source": [
    "print(type(env.behavior_specs[behavior_name]))\n",
    "print()\n",
    "print(env.behavior_specs[behavior_name])\n",
    "spec = env.behavior_specs[behavior_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "94ae7128",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "\n",
      "<class 'tuple'>\n",
      "ObservationSpec(shape=(8,), dimension_property=(<DimensionProperty.UNSPECIFIED: 0>,), observation_type=<ObservationType.DEFAULT: 0>, name='')\n"
     ]
    }
   ],
   "source": [
    "print(type(spec.observation_specs))\n",
    "print()\n",
    "print(type(tuple(spec.observation_specs[0])))\n",
    "print(spec.observation_specs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "744456f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'mlagents_envs.base_env.ActionSpec'>\n",
      "\n",
      "Continuous: 2, Discrete: ()\n"
     ]
    }
   ],
   "source": [
    "print(type(spec.action_spec))\n",
    "print()\n",
    "print(spec.action_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b48ea9be",
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_steps, terminal_steps = env.get_steps(behavior_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c294e4df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<mlagents_envs.base_env.DecisionSteps object at 0x000001F7E26460A0>\n",
      "[0]\n"
     ]
    }
   ],
   "source": [
    "print(decision_steps)\n",
    "print(list(decision_steps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "79fa77e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "tracked_agent = -1\n",
    "done = False\n",
    "episode_rewards = 0\n",
    "\n",
    "print(type(decision_steps.agent_id))\n",
    "tracked_agent = decision_steps.agent_id[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7f87cab9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "[[-0.98035    -0.04746135]]\n"
     ]
    }
   ],
   "source": [
    "action = spec.action_spec.random_action(len(decision_steps))\n",
    "print(type(action.continuous))\n",
    "print(action.continuous)\n",
    "# action = action.continuous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "00c6390a",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.set_actions(behavior_name, action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5a125601",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rewards for episode 0 is 1.0000000298023224\n",
      "Total rewards for episode 1 is 0.10000001639127731\n",
      "Total rewards for episode 2 is 0.700000025331974\n",
      "Total rewards for episode 3 is 0.700000025331974\n",
      "Total rewards for episode 4 is 2.0000000447034836\n",
      "Total rewards for episode 5 is 0.6000000238418579\n",
      "Total rewards for episode 6 is 1.500000037252903\n",
      "Total rewards for episode 7 is 1.1000000312924385\n",
      "Total rewards for episode 8 is 0.40000002086162567\n",
      "Total rewards for episode 9 is 0.30000001937150955\n",
      "Total rewards for episode 10 is 0.8000000268220901\n",
      "Total rewards for episode 11 is 0.6000000238418579\n",
      "Total rewards for episode 12 is 0.6000000238418579\n",
      "Total rewards for episode 13 is 1.1000000312924385\n",
      "Total rewards for episode 14 is 1.7000000402331352\n",
      "Total rewards for episode 15 is 0.6000000238418579\n",
      "Total rewards for episode 16 is 0.5000000223517418\n",
      "Total rewards for episode 17 is 1.8000000417232513\n",
      "Total rewards for episode 18 is 2.7000000551342964\n",
      "Total rewards for episode 19 is 0.9000000283122063\n",
      "Total rewards for episode 20 is 0.5000000223517418\n",
      "Total rewards for episode 21 is 1.500000037252903\n",
      "Total rewards for episode 22 is 0.9000000283122063\n",
      "Total rewards for episode 23 is 0.5000000223517418\n",
      "Total rewards for episode 24 is 2.0000000447034836\n",
      "Total rewards for episode 25 is 0.5000000223517418\n",
      "Total rewards for episode 26 is 1.0000000298023224\n",
      "Total rewards for episode 27 is 1.8000000417232513\n",
      "Total rewards for episode 28 is 0.9000000283122063\n",
      "Total rewards for episode 29 is 0.30000001937150955\n"
     ]
    }
   ],
   "source": [
    "for episode in range(30):\n",
    "    env.reset()\n",
    "    decision_steps, terminal_steps = env.get_steps(behavior_name)\n",
    "    tracked_agent = -1 # -1 indicates not yet tracking\n",
    "    done = False # For the tracked_agent\n",
    "    episode_rewards = 0 # For the tracked_agent\n",
    "    while not done:\n",
    "        # Track the first agent we see if not tracking\n",
    "        # Note : len(decision_steps) = [number of agents that requested a decision]\n",
    "        if tracked_agent == -1 and len(decision_steps) >= 1:\n",
    "            tracked_agent = decision_steps.agent_id[0]\n",
    "        # Generate an action for all agents\n",
    "        # action = spec.create_random_action(len(decision_steps))\n",
    "        action = spec.action_spec.random_action(len(decision_steps))\n",
    "        # Set the actions\n",
    "        env.set_actions(behavior_name, action)\n",
    "        # Move the simulation forward\n",
    "        env.step()\n",
    "        # Get the new simulation results\n",
    "        decision_steps, terminal_steps = env.get_steps(behavior_name)\n",
    "        if tracked_agent in decision_steps: # The agent requested a decision\n",
    "            episode_rewards += decision_steps[tracked_agent].reward\n",
    "#             print(decision_steps[tracked_agent].reward)\n",
    "        if tracked_agent in terminal_steps: # The agent terminated its episode\n",
    "            episode_rewards += terminal_steps[tracked_agent].reward\n",
    "#             print(terminal_steps[tracked_agent].reward)\n",
    "            done = True\n",
    "    print(f\"Total rewards for episode {episode} is {episode_rewards}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "be82a398",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
